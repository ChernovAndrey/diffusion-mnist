{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "import torch\nimport torchvision\nfrom torch.utils.data import DataLoader\nfrom matplotlib import pyplot as plt\nimport torchvision.transforms as transforms\n\ndevice = torch.device(\n    \"cuda\" if torch.cuda.is_available()\n    else \"mps\" if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f'Using device: {device}')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from AE import ConvAE, train_AE\nfrom diffusion import DiffusionNet, train_diffusion, sample, compute_latent_stats",
   "id": "a410a2ef22127d2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    root=\"mnist/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ],
   "id": "cea78dc22ac16d7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_dataloader = DataLoader(dataset, batch_size=8)",
   "id": "e2b5a15f51a5ba1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x, y = next(iter(train_dataloader))\n",
    "print('Input shape:', x.shape)\n",
    "print('Labels:', y)\n",
    "plt.imshow(torchvision.utils.make_grid(x)[0], cmap='Greys');"
   ],
   "id": "95382249c1a48916",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=2048, shuffle=True, pin_memory=True,\n",
    "                              num_workers=8, persistent_workers=True)"
   ],
   "id": "ed921322cf3acec3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# hyperparameters\nlatent_channels = 64  # token_dim — must match AE\nT = 100  # diffusion timesteps\nn_layers = 4  # transformer layers\nn_heads = 4  # attention heads (128 / 4 = 32 per head)\nmlp_size = 512  # FFN intermediate size\ndropout_rate = 0.05\nlr_ae = 1e-3\nlr_diff = 5e-4\nae_epochs = 20\ndiff_epochs = 200",
   "id": "ed049b7cd5aba0e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_AE = ConvAE(latent_channels=latent_channels)\nprint(f\"ConvAE: {model_AE.n_tokens} tokens x {model_AE.token_dim} dim\")",
   "id": "becf97ecc6fc36d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_AE(model_AE, ae_epochs, train_dataloader, lr=lr_ae, device=device)",
   "id": "3902aa711b09068a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2k3edz96mnu",
   "source": "# visualize AE reconstructions\nmodel_AE.eval()\nwith torch.no_grad():\n    x_sample, _ = next(iter(train_dataloader))\n    x_sample = x_sample[:8].to(device)\n    recon, _ = model_AE(x_sample)\n    recon = torch.sigmoid(recon)\n\nfig, axes = plt.subplots(2, 8, figsize=(16, 4))\nfor i in range(8):\n    axes[0, i].imshow(x_sample[i, 0].detach().cpu(), cmap='Greys')\n    axes[0, i].axis('off')\n    axes[1, i].imshow(recon[i, 0].detach().cpu(), cmap='Greys')\n    axes[1, i].axis('off')\naxes[0, 0].set_title('Original')\naxes[1, 0].set_title('Reconstructed')\nplt.tight_layout()",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "gju818z9cc5",
   "source": "# compute latent stats for normalization\nlatent_mean, latent_std = compute_latent_stats(model_AE, train_dataloader, device)\nprint(f\"Latent mean range: [{latent_mean.min():.3f}, {latent_mean.max():.3f}]\")\nprint(f\"Latent std range:  [{latent_std.min():.3f}, {latent_std.max():.3f}]\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "diff_model = DiffusionNet(\n    token_dim=latent_channels,    # 64 — matches AE\n    hidden_size=128,              # internal transformer width\n    n_layers=n_layers,\n    n_heads=n_heads,\n    dropout_rate=dropout_rate,\n    mlp_size=mlp_size,\n    T=T,\n)\nprint(f\"DiffusionNet params: {sum(p.numel() for p in diff_model.parameters()):,}\")",
   "id": "85a1fe705a1c9d60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_diffusion(diff_model, model_AE, diff_epochs, train_dataloader, T, lr=lr_diff,\n                latent_mean=latent_mean, latent_std=latent_std, device=device)",
   "id": "29fd575dde2ce463",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "generated = sample(\n    diff_model, model_AE,\n    n_samples=16, T=T,\n    n_tokens=model_AE.n_tokens,\n    token_dim=model_AE.token_dim,\n    latent_mean=latent_mean,\n    latent_std=latent_std,\n    device=device,\n)\n\nfig, axes = plt.subplots(2, 8, figsize=(16, 4))\nfor i in range(16):\n    axes[i // 8, i % 8].imshow(generated[i, 0].detach().cpu(), cmap='Greys')\n    axes[i // 8, i % 8].axis('off')\nplt.suptitle('Generated MNIST Digits')\nplt.tight_layout()",
   "id": "1a0dff838a1efc1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5e2d7b75904b94e2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
